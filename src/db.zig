const std = @import("std");
const assert = std.debug.assert;
const Allocator = std.mem.Allocator;
const StructField = std.builtin.Type.StructField;
const Engine = @import("llrb");
const RBTree = Engine.Tree;

pub fn DBType(comptime config: anytype) type {
    assert(@hasField(@TypeOf(config), "tables"));
    assert(@hasField(@TypeOf(config), "indexes"));

    const Tables = @typeInfo(@TypeOf(config.tables)).@"struct";

    const Indexes = config.indexes;

    var struct_fields: [Tables.fields.len]StructField = undefined;
    for (Tables.fields, 0..) |field, i| {
        const table_name = field.name;
        const TableSchema = @field(config.tables, table_name);

        const TableId = @FieldType(TableSchema, "id");

        const IndexedFields = if (@hasField(@TypeOf(Indexes), table_name)) @field(Indexes, table_name) else .{};

        const CrudOps = crud_for_table(TableSchema, TableId, IndexedFields);
        const crud: CrudOps = .{};

        struct_fields[i] = .{ .name = table_name, .type = CrudOps, .default_value_ptr = &crud, .is_comptime = false, .alignment = @alignOf(CrudOps) };
    }

    const Schema = @Type(.{ .@"struct" = .{
        .layout = .auto,
        .fields = &struct_fields,
        .decls = &.{},
        .is_tuple = false,
    } });
    return Schema;
}

fn crud_for_table(comptime Table: anytype, TableId: anytype, comptime IndexBlock: anytype) type {
    return struct {
        const Self = @This();
        pub const Indexes = generate_indexes(Table, IndexBlock);
        pub const Tree = RBTree(TableId, Table, compare_fn);
        pub const UpsertResult = struct { table_id: TableId, found_in_table: bool };
        pub const Error = error{fullDatabase};
        pub const MAX_IDX = Engine.MAX_IDX;

        store: Tree = .empty,
        ///Do not modify. Stores the last id generated by the system
        last_id: u64 = 0,
        indexes: Indexes = .{},

        pub fn get(self: *Self, id: TableId) ?Table {
            return self.store.get(id);
        }

        ///Creates a new entry in the database. Asserts that there is space for a new insertion
        ///
        ///Because the primary identifier for a table is a monotonically incremented id, we are guaranteed to have no conflicts
        pub fn createAssumeCapacity(self: *Self, object: Table) TableId {
            self.last_id += 1;
            const id = self.last_id;
            var obj = object;
            obj.id = @enumFromInt(id);

            assert(self.store.nodes.items.len < MAX_IDX);

            inline for (@typeInfo(Indexes).@"struct".fields) |f| {
                assert(@hasField(Table, f.name));
                const index_tree = &@field(self.indexes, f.name);
                assert(index_tree.nodes.items.len < MAX_IDX);
            }

            self.store.insertAssumeCapacity(.{ .key = obj.id, .value = obj }) catch unreachable;

            inline for (@typeInfo(Indexes).@"struct".fields) |f| {
                var index_tree = &@field(self.indexes, f.name);
                index_tree.insertAssumeCapacity(.{ .key = .{ .field_value = @field(obj, f.name), .record_id = obj.id }, .value = 1 }) catch unreachable;
            }

            return obj.id;
        }

        ///Creates a new entry in the database, allocating the space for it
        pub fn create(self: *Self, allocator: Allocator, object: Table) !TableId {
            try self.reserve(allocator, 1);
            return self.createAssumeCapacity(object);
        }

        ///Reserves space for new entries in the database storage and index trees
        pub fn reserve(self: *Self, allocator: Allocator, count: usize) !void {
            if (self.store.nodes.items.len == MAX_IDX) return Error.fullDatabase;
            try self.store.reserveCapacity(allocator, count);

            inline for (@typeInfo(Indexes).@"struct".fields) |f| {
                assert(@hasField(Table, f.name));
                var index_tree = &@field(self.indexes, f.name);
                assert(index_tree.nodes.items.len < MAX_IDX);
                try index_tree.reserveCapacity(allocator, count);
            }
        }

        pub fn compare_fn(a: TableId, b: TableId) std.math.Order {
            return std.math.order(@intFromEnum(a), @intFromEnum(b));
        }

        pub fn filter(self: *Self, query: anytype, buf: []Table) ?[]Table {
            const Query = @TypeOf(query);
            const query_fields = @typeInfo(Query).@"struct".fields;

            const index_iterators, const non_indexed_fields = blk: {
                comptime var indexed_fields: [query_fields.len][]const u8 = undefined;
                comptime var non_indexed_fields: [query_fields.len][]const u8 = undefined;

                comptime var indexed_field_count = 0;
                comptime var non_indexed_count = 0;

                //Go through the query fields, and separate the indexed fields from the non-indexed fields in the query
                inline for (query_fields) |f| {
                    if (!@hasField(Table, f.name)) @compileError("Table does not have field '" ++ f.name ++ "'");
                    if (@hasField(Indexes, f.name)) {
                        indexed_fields[indexed_field_count] = f.name;
                        indexed_field_count += 1;
                    } else {
                        non_indexed_fields[non_indexed_count] = f.name;
                        non_indexed_count += 1;
                    }
                }

                //Generate a tuple which can store the different index iterators for this query
                comptime var index_iterator_types: [indexed_field_count]type = undefined;
                inline for (indexed_fields[0..indexed_field_count], 0..) |name, i| {
                    const IndexType = @FieldType(Indexes, name);
                    index_iterator_types[i] = IndexType.Iterator;
                }
                const TupleOfIndexIteratorTypes = std.meta.Tuple(&index_iterator_types);

                //Populate the tuple with the actual iterators for each index
                var index_iterators: TupleOfIndexIteratorTypes = undefined;
                inline for (indexed_fields[0..indexed_field_count], 0..indexed_field_count) |name, i| {
                    const index = @field(self.indexes, name);
                    const IndexKey = @FieldType(Indexes, name).Key;

                    const query_value = @field(query, name);
                    const IdInt = @typeInfo(@FieldType(IndexKey, "record_id")).@"enum".tag_type;

                    const min_id: IdInt = 0;
                    const max_id: IdInt = std.math.maxInt(IdInt);

                    index_iterators[i] = index.rangeIterator(
                        .{ .field_value = query_value, .record_id = @enumFromInt(min_id) },
                        .{ .field_value = query_value, .record_id = @enumFromInt(max_id) },
                    );
                }

                break :blk .{ index_iterators, non_indexed_fields[0..non_indexed_count].* };
            };

            var count: usize = 0;

            //Now the intersection between the different iterators
            //Thank you, Matklad. https://matklad.github.io/2025/03/19/comptime-zig-orm.html#Merge-Sort-Join
            loop: while (true) {
                //Check if we've filled the output buffer
                if (count == buf.len) break;

                const pk = index_iterators[0].peek() orelse break;
                var min = pk.record_id;

                //Get the iterator with the lowest record_id
                inline for (index_iterators) |iterator| {
                    const peek = iterator.peek() orelse break;

                    if (compare_values(peek.record_id, min) == .lt) {
                        min = peek.record_id;
                    }
                }

                //Advance all the iterators which match the lowest record_id
                var matched_count: u32 = 0;
                inline for (&index_iterators) |*iterator| {
                    //We just passed it in the previous loop. There's no way it can be null
                    if (compare_values(iterator.peek().?.record_id, min) == .eq) {
                        @constCast(iterator).advance();
                        matched_count += 1;
                    }
                }

                //If all the iterators were advanced, then this record is a match
                if (matched_count == index_iterators.len) {
                    const record = self.store.get(min) orelse std.debug.panic("Indexes are out of sync with the database storage for record with id:{}\n", .{min});

                    inline for (non_indexed_fields) |field_name| {
                        const query_value = @field(query, field_name);
                        if (@field(record, field_name) != query_value) continue :loop;
                    }
                    buf[count] = record;
                    count += 1;
                }
            }

            if (buf.len == 0) return null else return buf[0..count];
        }

        pub fn update(self: *Self, fields: Table) void {
            const old = self.store.get(fields.id) orelse {
                std.debug.print("No entity with the id:{} found in the table", .{fields.id});
                return;
            };

            _ = self.store.update(.{ .key = fields.id, .value = fields }) catch {
                std.debug.print("Update failed", .{});
                return;
            }; //the update failed. no need to modify the index

            const UpdatedFields = @typeInfo(@TypeOf(fields)).@"struct".fields;

            inline for (0..UpdatedFields.len) |i| {
                const f = UpdatedFields[i];
                comptime if (std.mem.eql(u8, f.name, "id")) continue;
                if (!@hasField(Indexes, f.name)) continue;

                const Index = @FieldType(Indexes, f.name);
                const IndexKey = Index.Key;

                //Get the index tree and delete the old entry
                const old_key: IndexKey = .{ .field_value = @field(old, f.name), .record_id = fields.id };
                var field_index_tree = &@field(self.indexes, f.name);

                _ = field_index_tree.delete(old_key) orelse {
                    std.debug.panic("database entry without index entry: {}\n", .{old_key});
                };

                //Construct and insert the new index entry with the updated value
                const new_index_entry: Index.KV = .{ .key = .{ .field_value = @field(fields, f.name), .record_id = fields.id }, .value = 1 };

                field_index_tree.insertAssumeCapacity(new_index_entry) catch unreachable;
            }

            return;
        }

        ///Returns a slice to the table entries
        ///
        ///Any modifications to the data here affects the items in the table. Take care to avoid corruption
        pub fn slice(self: *Self) []Table {
            return self.store.values.items;
        }
        pub fn delete(self: *Self, id: TableId) ?Table {
            _ = self;
            _ = id;
        }

        pub fn deinit(self: *Self, gpa: Allocator) void {
            self.store.deinit(gpa);
            inline for (@typeInfo(Indexes).@"struct".fields) |f| {
                var index = @field(self.indexes, f.name);
                index.deinit(gpa);
            }
        }
    };
}

fn generate_indexes(comptime Table: type, comptime IndexBlock: anytype) type {
    const index_info = @typeInfo(@TypeOf(IndexBlock)).@"struct";
    var fields: [index_info.fields.len]std.builtin.Type.StructField = undefined;

    for (index_info.fields, 0..) |_, i| {
        const field_name = @tagName(IndexBlock[i]);
        if (!@hasField(Table, field_name)) {
            @compileError("Table " ++ @typeName(Table) ++
                " has no field '" ++ field_name ++ "'");
        }

        const FieldType = @FieldType(Table, field_name);

        const KeyType = struct {
            field_value: FieldType,
            record_id: Table.ID,
        };
        const compare = struct {
            fn cmp(a: KeyType, b: KeyType) std.math.Order {
                const val_cmp = compare_values(a.field_value, b.field_value);
                if (val_cmp != .eq) return val_cmp;
                return std.math.order(@intFromEnum(a.record_id), @intFromEnum(b.record_id));
            }
        }.cmp;

        //This is wasteful. Find a way around it.
        //Using a void type as the value of the tree causes issues with arraylist growth due to void having a size of 0
        const IndexTree = RBTree(KeyType, u8, compare);

        fields[i] = .{
            .name = field_name,
            .type = IndexTree,
            .default_value_ptr = &IndexTree.empty,
            .is_comptime = false,
            .alignment = @alignOf(IndexTree),
        };
    }

    return @Type(.{
        .@"struct" = .{
            .layout = .auto,
            .fields = &fields,
            .decls = &.{},
            .is_tuple = false,
        },
    });
}

fn compare_values(a: anytype, b: @TypeOf(a)) std.math.Order {
    const T = @TypeOf(a);
    return switch (@typeInfo(T)) {
        .int, .float, .comptime_int, .comptime_float => std.math.order(a, b),
        .@"enum" => std.math.order(@intFromEnum(a), @intFromEnum(b)),
        .bool => std.math.order(@intFromBool(a), @intFromBool(b)),
        .pointer => |pointerInfo| {
            if (pointerInfo.child == u8 and pointerInfo.size == .slice) return std.mem.order(u8, a, b);
            @compileError("Unsupported type for index: " ++ @typeName(T));
        },
        else => @compileError("Unsupported type for index: " ++ @typeName(T)),
    };
}

pub fn deinit(db: anytype, allocator: Allocator) void {
    const info = @typeInfo(@TypeOf(db));
    if (info != .pointer) {
        @compileError("A non-pointer type was passed to db.deinit");
    }
    const tp_info = info.pointer;

    if (tp_info.size != .one or @typeInfo(tp_info.child) != .@"struct") {
        @compileError("A pointer to an invalid type was passed to db.deinit");
    }

    const tables = @TypeOf(db.*);
    inline for (@typeInfo(tables).@"struct".fields) |t| {
        var table = @field(db.*, t.name);
        table.deinit(allocator);
    }
}
